# Healthcare AI Assistant - Technical Architecture & Demo

## Executive Summary

This document outlines the technical solution for an AI-powered assistant that integrates with existing healthcare data modules to provide intelligent data analysis, visualization, and reporting capabilities through natural language interactions. **A fully functional demo with LLM integration is included to showcase the core concepts.**

## Project Structure

```
healthcare_ai_assistant_architecture/
‚îú‚îÄ‚îÄ README.md                 # This comprehensive documentation
‚îú‚îÄ‚îÄ demo_app.py              # Streamlit demo application (56KB)
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies for demo
‚îú‚îÄ‚îÄ run_demo.py             # Quick setup and run script
‚îú‚îÄ‚îÄ test_demo.py            # Component testing script
‚îî‚îÄ‚îÄ healthcare_demo.db      # SQLite database (auto-generated)
```

## Quick Start - Try the Demo

**Ready to see it in action? Start the demo immediately:**

```bash
# Option 1: Quick start (installs dependencies automatically)
python run_demo.py

# Option 2: Manual setup
pip install -r requirements.txt
streamlit run demo_app.py

# Option 3: Test components first
python test_demo.py
```

**Then open your browser to `http://localhost:8501` and try these queries:**
- Show me sales trends for Aspirin
- Compare all drug performance
- Which is our best selling drug?
- Tell me something interesting about our business

The demo includes **intelligent query processing** with conversational flow:

- **LLM-First Architecture**: Proper conversation vs analysis detection
- **Function Calling**: LLM intelligently decides when to analyze data
- **Smart Processing**: Enhanced fallback mode - works perfectly even without LLM connection

---

## System Overview

### Current System Components
- **Personal Data Module**: User profile and preferences management
- **Widget Configuration System**: Dashboard creation and widget management
- **Data Module**: Sales data storage and retrieval API

### Proposed Architecture Components

## 1. Core AI Assistant Architecture

### 1.1 AI Assistant Gateway
**Purpose**: Central entry point for all user interactions
**Technology**: Node.js/Python FastAPI with WebSocket support
**Responsibilities**:
- User authentication and session management
- Request routing and response aggregation
- Real-time communication with frontend
- Rate limiting and security enforcement

### 1.2 Natural Language Understanding (NLU) Service
**Technology**: Microservice architecture with containerized deployment
**Components**:

#### Intent Classification Model
- **Model Type**: Fine-tuned BERT/RoBERTa or GPT API
- **Purpose**: Classify user requests into predefined business intents
- **Training Data**: Business domain-specific intents (sales analysis, trend analysis, comparison, etc.)
- **Intents Examples**:
  - `SALES_TREND_ANALYSIS`
  - `COMPARATIVE_ANALYSIS`
  - `TEMPORAL_BREAKDOWN`
  - `VISUALIZATION_REQUEST`

#### Named Entity Recognition (NER) Model
- **Model Type**: spaCy with custom healthcare domain model or fine-tuned BERT-NER
- **Purpose**: Extract business entities from user queries
- **Entities**:
  - Drug names (Aspirin, Medication X)
  - Time periods (last 3 months, yearly, weekly)
  - Regions (countries, areas)
  - Chart types (bar, line, pie)
  - Metrics (sales, quantity, amount)

#### Query Parameter Extraction
- **Technology**: Rule-based system + ML model
- **Purpose**: Convert extracted entities into structured API parameters
- **Output**: JSON structure with filters, time ranges, grouping criteria

### 1.3 Business Logic Orchestrator
**Technology**: Python with Celery for async processing
**Purpose**: Coordinate data retrieval, analysis, and response generation
**Components**:

#### Workflow Engine
- **Technology**: Apache Airflow or custom workflow system
- **Purpose**: Define and execute multi-step business processes
- **Features**:
  - Dynamic workflow generation based on intent
  - Error handling and retry mechanisms
  - Progress tracking for long-running operations

#### Data Integration Service
- **Purpose**: Unified interface to all data sources
- **Features**:
  - API adapters for each existing module
  - Data transformation and normalization
  - Caching layer for frequently accessed data
  - Data validation and quality checks

### 1.4 Analytics and Visualization Engine
**Technology**: Python with pandas, NumPy, matplotlib/plotly
**Components**:

#### Statistical Analysis Module
- **Libraries**: SciPy, statsmodels, scikit-learn
- **Capabilities**:
  - Trend analysis (linear regression, time series decomposition)
  - Comparative analysis (t-tests, ANOVA)
  - Forecasting (ARIMA, exponential smoothing)
  - Anomaly detection

#### Visualization Generator
- **Technology**: Plotly/D3.js for interactive charts
- **Chart Types**: Bar, line, pie (extensible)
- **Features**:
  - Responsive design for different screen sizes
  - Interactive elements (zoom, filter, drill-down)
  - Export capabilities (PNG, PDF, SVG)

#### Natural Language Generation (NLG)
- **Model Type**: GPT API or fine-tuned T5/BART
- **Purpose**: Generate human-readable insights and explanations
- **Capabilities**:
  - Summarize statistical findings
  - Explain trends and patterns
  - Provide actionable recommendations

## 2. Data Architecture

### 2.1 Assistant Configuration Database
**Technology**: PostgreSQL
**Purpose**: Store assistant configuration and behavior settings
**Schema**:
```sql
-- Intent definitions and configurations
CREATE TABLE intents (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE,
    description TEXT,
    workflow_template JSONB,
    is_active BOOLEAN DEFAULT true
);

-- User preferences and permissions
CREATE TABLE user_assistant_config (
    user_id UUID PRIMARY KEY,
    default_visualization_type VARCHAR(20),
    preferred_time_range VARCHAR(50),
    accessible_regions JSONB,
    custom_prompts JSONB
);

-- Query history and learning data
CREATE TABLE query_history (
    id SERIAL PRIMARY KEY,
    user_id UUID,
    original_query TEXT,
    parsed_intent VARCHAR(100),
    extracted_entities JSONB,
    execution_time TIMESTAMP,
    success BOOLEAN,
    feedback_score INTEGER
);
```

### 2.2 Cache Layer
**Technology**: Redis
**Purpose**: High-performance caching for frequently accessed data
**Cache Types**:
- API response caching (TTL: 15-60 minutes)
- User session data
- Pre-computed analytics results
- ML model predictions

### 2.3 Analytics Results Store
**Technology**: InfluxDB (time-series) + MongoDB (documents)
**Purpose**: Store computed analytics and generated visualizations
**Structure**:
- Time-series metrics and KPIs
- Generated chart configurations
- Historical analysis results
- Performance benchmarks

## 3. AI/ML Models Details

### 3.1 Intent Classification Model
**Architecture**: 
```
Input: "Show sales for the year, break it down by weeks, and display it in a bar chart"
‚Üì
BERT Encoder ‚Üí Classification Head ‚Üí Softmax
‚Üì
Output: {
  "intent": "TEMPORAL_BREAKDOWN_VISUALIZATION",
  "confidence": 0.95
}
```

**Training Strategy**:
- Initial training on general business query datasets
- Fine-tuning on healthcare/pharmaceutical domain data
- Active learning with user feedback

### 3.2 Entity Extraction Pipeline
**Architecture**:
```
Input Text ‚Üí Tokenization ‚Üí BERT-NER ‚Üí Post-processing Rules
‚Üì
Output: {
  "drug": ["Aspirin"],
  "time_period": ["year", "weeks"],
  "chart_type": ["bar"],
  "metric": ["sales"]
}
```

### 3.3 Recommendation Engine
**Model Type**: Collaborative Filtering + Content-based
**Purpose**: Suggest relevant analyses and visualizations
**Features**:
- User behavior analysis
- Similar query recommendations
- Proactive insights based on data patterns

### 3.4 Anomaly Detection Model
**Model Type**: Isolation Forest + LSTM for time series
**Purpose**: Automatically detect unusual patterns in data
**Implementation**:
- Real-time anomaly scoring
- Threshold-based alerting
- Historical pattern learning

## 4. Service Architecture

### 4.1 Microservices Design
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web Frontend  ‚îÇ    ‚îÇ  Mobile App     ‚îÇ    ‚îÇ  Admin Panel    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  API Gateway    ‚îÇ
                    ‚îÇ  (Auth, Rate    ‚îÇ
                    ‚îÇ   Limiting)     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ AI Assistant    ‚îÇ
                    ‚îÇ   Gateway       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                       ‚îÇ                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ NLU Service     ‚îÇ    ‚îÇ Business Logic  ‚îÇ    ‚îÇ Analytics &     ‚îÇ
‚îÇ - Intent Cls.   ‚îÇ    ‚îÇ Orchestrator    ‚îÇ    ‚îÇ Visualization   ‚îÇ
‚îÇ - NER           ‚îÇ    ‚îÇ - Workflow Eng. ‚îÇ    ‚îÇ - Stats Analysis‚îÇ
‚îÇ - Param Extract ‚îÇ    ‚îÇ - Data Integr.  ‚îÇ    ‚îÇ - Chart Gen.    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Data Integration‚îÇ
                    ‚îÇ    Service      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                       ‚îÇ                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Personal Data   ‚îÇ    ‚îÇ Widget Config   ‚îÇ    ‚îÇ  Data Module    ‚îÇ
‚îÇ   Module        ‚îÇ    ‚îÇ    System       ‚îÇ    ‚îÇ  (Sales Data)   ‚îÇ
‚îÇ (Existing)      ‚îÇ    ‚îÇ  (Existing)     ‚îÇ    ‚îÇ  (Existing)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.2 Data Flow Architecture
```
User Query ‚Üí NLU ‚Üí Intent + Entities ‚Üí Workflow ‚Üí Data APIs ‚Üí Analysis ‚Üí Visualization + NLG ‚Üí Response
```

## 5. Integration Strategy

### 5.1 API Integration Layer
**Technology**: GraphQL Federation or REST API Gateway
**Features**:
- Unified schema across all modules
- Automatic API documentation
- Version management
- Circuit breakers for fault tolerance

### 5.2 Event-Driven Architecture
**Technology**: Apache Kafka or Redis Streams
**Events**:
- User query received
- Analysis completed
- Data updated
- Configuration changed

## 6. Admin Panel Features

### 6.1 Assistant Configuration
- Intent management (add/edit/disable intents)
- NLU model training data management
- Workflow template editor
- Performance monitoring dashboard

### 6.2 User Management
- User permissions and access control
- Usage analytics and reporting
- Feedback collection and analysis

### 6.3 System Monitoring
- Service health monitoring
- API performance metrics
- ML model accuracy tracking
- Resource utilization

## 7. Extensibility Framework

### 7.1 Plugin Architecture
```python
class AnalysisPlugin:
    def can_handle(self, intent: str, entities: dict) -> bool:
        pass
    
    def execute(self, data: DataFrame, params: dict) -> AnalysisResult:
        pass
    
    def get_visualization_config(self) -> dict:
        pass
```

### 7.2 Custom Model Integration
- Model registry for different AI models
- A/B testing framework for model improvements
- Hot-swapping capabilities for model updates

## 8. Technology Stack Summary

### Backend Services
- **API Gateway**: Kong or AWS API Gateway
- **Microservices**: Python FastAPI / Node.js
- **AI/ML**: PyTorch/TensorFlow, Hugging Face Transformers
- **Workflow**: Apache Airflow
- **Message Queue**: Apache Kafka or Redis

### Data Storage
- **Primary DB**: PostgreSQL
- **Cache**: Redis
- **Time-series**: InfluxDB
- **Document Store**: MongoDB

### Frontend
- **Web**: React.js with TypeScript
- **Mobile**: React Native or Flutter
- **Charts**: Plotly.js or D3.js

### Infrastructure
- **Containerization**: Docker + Kubernetes
- **Monitoring**: Prometheus + Grafana
- **Logging**: ELK Stack (Elasticsearch, Logstash, Kibana)
- **CI/CD**: Jenkins or GitLab CI

### Demo Stack (Simplified)
- **Backend**: Python with Streamlit
- **Database**: SQLite
- **Analytics**: Pandas + NumPy
- **Visualization**: Plotly
- **NLU**: LLM (OpenAI) + Rule-based fallback

## 9. Security and Compliance

### 9.1 Data Security
- End-to-end encryption for sensitive healthcare data
- RBAC (Role-Based Access Control)
- API authentication with JWT tokens
- Data anonymization for ML training

### 9.2 Compliance
- HIPAA compliance for healthcare data
- GDPR compliance for EU users
- Audit logging for all data access
- Data retention and deletion policies

## 10. Key Benefits and Advantages

### Business Benefits
1. **Reduced Analysis Time**: From hours to minutes for complex queries
2. **Democratized Analytics**: Non-technical users can perform sophisticated analysis
3. **Consistent Insights**: Standardized analytical approaches across the organization
4. **Proactive Intelligence**: Automatic anomaly detection and recommendations

### Technical Benefits
1. **Seamless Integration**: Non-intrusive connection to existing systems
2. **Scalable Architecture**: Independent scaling of AI components
3. **Future-Proof Design**: Plugin architecture for easy feature additions
4. **Enterprise Security**: Healthcare-compliant data handling

### User Experience Benefits
1. **Natural Language Interface**: Intuitive interaction without learning complex tools
2. **Multi-Modal Output**: Text, charts, and interactive visualizations
3. **Personalized Experience**: User preferences and role-based access
4. **Real-Time Processing**: Immediate responses to business questions

---

This comprehensive architecture provides a robust foundation for your healthcare AI assistant with a **working demo** that proves the concept. The demo demonstrates all core capabilities in a simplified but functional implementation, ready for immediate testing and further development.

**üöÄ Start exploring now with `python run_demo.py`!**

---

## üéÆ Demo Implementation

### Features Showcased

The included demo implements simplified versions of the key architectural components:

#### ü§ñ AI-Powered Chat Interface
- Natural language query processing with Streamlit
- **LLM-enhanced understanding** for complex queries
- Intent classification and entity extraction
- Context-aware responses with data insights
- Real-time chart integration

#### üìä Analytics Capabilities
- **Sales Trend Analysis**: Track performance over time with line charts
- **Comparative Analysis**: Compare drug performance with bar charts
- **Regional Analysis**: Geographic breakdowns with pie charts
- **Interactive Visualizations**: Plotly-powered responsive charts

#### üóÑÔ∏è Sample Database
- **1000+ Sales Records**: Realistic pharmaceutical data spanning 12 months
- **8 Drug Portfolio**: Different categories (Pain Relief, Cardiovascular, etc.)
- **4 Geographic Regions**: North America, Europe, Asia, South America
- **Representative Data**: Sales team performance tracking

### Demo Architecture Alignment

| Full Architecture Component | Demo Implementation |
|----------------------------|-------------------|
| AI Assistant Gateway | Streamlit main interface |
| NLU Service | **Enhanced**: LLM + Rule-based fallback |
| Business Logic Orchestrator | `AnalyticsEngine` class |
| Data Integration Service | `HealthcareDatabase` class with SQLite |
| Visualization Engine | Plotly chart generation |
| Chat Interface | Streamlit chat components |
| Database Layer | SQLite with realistic sample data |

### Conversation Context & Memory

The demo showcases advanced conversation capabilities:

#### **Context-Aware Follow-ups**
```
User: "Show me sales trends for Aspirin"
AI: [Generates trend analysis]

User: "What about for Europe specifically?"
AI: [Shows same analysis filtered for Europe]

User: "Now show that for Ibuprofen"
AI: [Analyzes Ibuprofen trends with Europe filter maintained]
```

#### **Natural Conversation Flow**
- **Greetings**: "Hello" ‚Üí Natural welcome response
- **Follow-ups**: "What about..." ‚Üí Context-aware analysis
- **Parameter Switching**: "Show that for Asia" ‚Üí Inherits analysis type
- **Conversation Memory**: Maintains context throughout session

**üè• Healthcare AI Assistant - Making data analysis as easy as having a conversation!**